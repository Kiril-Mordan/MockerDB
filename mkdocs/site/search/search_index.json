{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro","text":"<p>MockerDB</p> <p>A python module that contains mock vector database like solution built around dictionary data type. It contains methods necessary to interact with this 'database', embed, search and persist.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install mocker-db\n</code></pre>"},{"location":"cli/","title":"Cli","text":"<pre><code>mockerdb --help\n</code></pre> <pre><code>Usage: mockerdb [OPTIONS] COMMAND [ARGS]...\n\n  Mocker-db CLI tool\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  runserver  Run the FastAPI server for MockerDB.\n</code></pre> <p>Mocker-db exists as API that can be pulled from <code>dockerhub</code> as docker image. This pulls the code that functions within that docker image into some cached directory and runs uvicorn fastapi app from there, also saving mocker state there is persist path is not provided.</p> <pre><code>mockerdb runserver  --help\n</code></pre> <pre><code>Usage: mockerdb runserver [OPTIONS]\n\n  Run the FastAPI server for MockerDB.\n\nOptions:\n  --persist-path TEXT  Path where cache data will be saved. Path will be\n                       cached.\n  --repo-url TEXT      The URL of the GitHub repository to clone.\n  --host TEXT          The host to bind to.\n  --port INTEGER       The port to bind to.\n  --reload             Enable auto-reload.\n  --dump-cache         Overwrites existing cache.\n  --help               Show this message and exit.\n</code></pre>"},{"location":"flow/","title":"Flow","text":""},{"location":"release-notes/","title":"Release notes","text":""},{"location":"release-notes/#012","title":"0.1.2","text":"<pre><code>- initital cli interface that allows to clone code from api version of mocker and run it\n</code></pre>"},{"location":"release-notes/#011","title":"0.1.1","text":"<pre><code>- initial MockerConnect for using MockerDB API\n</code></pre>"},{"location":"release-notes/#0012","title":"0.0.12","text":"<pre><code>-  bugfix for similarity search through partly embedded data\n</code></pre>"},{"location":"release-notes/#0011","title":"0.0.11","text":"<pre><code>- more advanced filtering\n</code></pre>"},{"location":"release-notes/#0010","title":"0.0.10","text":"<pre><code>- fix for search without embeddings\n</code></pre>"},{"location":"release-notes/#006","title":"0.0.6","text":"<pre><code>- fix for embedding storage\n</code></pre>"},{"location":"release-notes/#005","title":"0.0.5","text":"<pre><code>- initial implementation of separate caching store for embeddings\n</code></pre>"},{"location":"release-notes/#004","title":"0.0.4","text":"<pre><code>- updating hnswlib 0.7.0 -&gt; 0.8.0 to fix vulnerabilities issue\n\n- fixing a bug with resetting mocker inner state properly after search\n</code></pre>"},{"location":"release-notes/#003","title":"0.0.3","text":"<pre><code>- slightly improving logic of embedding with batches in parallel for sentence transformer embedder (default embedder)\n\n- updating desciption\n</code></pre>"},{"location":"release-notes/#002","title":"0.0.2","text":"<pre><code>- better error handling in situations when data was not found with applied filters\n</code></pre>"},{"location":"release-notes/#001","title":"0.0.1","text":"<pre><code>- initial version of MockerDB package that evolved from mock classes from redis into a standalone solution\n</code></pre>"},{"location":"usage-examples/","title":"Mocker DB","text":"<p>This class is a mock handler for simulating a vector database, designed primarily for testing and development scenarios. It offers functionalities such as text embedding, hierarchical navigable small world (HNSW) search, and basic data management within a simulated environment resembling a vector database.</p> <pre><code>import sys\nimport numpy as np\nsys.path.append('../')\nfrom python_modules.mocker_db import MockerDB, SentenceTransformerEmbedder, MockerSimilaritySearch\n</code></pre>"},{"location":"usage-examples/#usage-examples","title":"Usage examples","text":"<p>The examples contain: 1. Basic data insertion and retrieval 2. Text embedding and searching 3. Advanced filtering and removal 4. Testing the HNSW search algorithm 5. Simulating database connection and persistence</p>"},{"location":"usage-examples/#1-basic-data-insertion-and-retrieval","title":"1. Basic Data Insertion and Retrieval","text":"<pre><code># Initialization\nhandler = MockerDB(\n    # optional\n    embedder_params = {'model_name_or_path' : 'paraphrase-multilingual-mpnet-base-v2',\n                        'processing_type' : 'batch',\n                        'tbatch_size' : 500},\n    embedder = SentenceTransformerEmbedder,\n    ## optional/ for similarity search\n    similarity_search_h = MockerSimilaritySearch,\n    return_keys_list = [],\n    search_results_n = 3,\n    similarity_search_type = 'linear',\n    similarity_params = {'space':'cosine'},\n    ## optional/ inputs with defaults\n    file_path = \"./mock_persist\",\n    persist = True,\n    embedder_error_tolerance = 0.0\n)\n# Initialize empty database\nhandler.establish_connection()\n\n# Insert Data\nvalues_list = [\n    {\"text\": \"Sample text 1\"},\n    {\"text\": \"Sample text 2\"}\n]\nhandler.insert_values(values_list, \"text\")\nprint(f\"Items in the database {len(handler.data)}\")\n\n# Retrieve Data\nhandler.filter_keys(subkey=\"text\", subvalue=\"Sample text 1\")\nhandler.search_database_keys(query='text')\nresults = handler.get_dict_results(return_keys_list=[\"text\"])\nprint(results)\n\n</code></pre> <pre><code>.gitattributes:   0%|          | 0.00/744 [00:00&lt;?, ?B/s]\n\n\n\n1_Pooling/config.json:   0%|          | 0.00/190 [00:00&lt;?, ?B/s]\n\n\n\nREADME.md:   0%|          | 0.00/4.13k [00:00&lt;?, ?B/s]\n\n\n\nconfig.json:   0%|          | 0.00/723 [00:00&lt;?, ?B/s]\n\n\n\nconfig_sentence_transformers.json:   0%|          | 0.00/122 [00:00&lt;?, ?B/s]\n\n\n\nmodel.safetensors:   0%|          | 0.00/1.11G [00:00&lt;?, ?B/s]\n\n\n\npytorch_model.bin:   0%|          | 0.00/1.11G [00:00&lt;?, ?B/s]\n\n\n\nsentence_bert_config.json:   0%|          | 0.00/53.0 [00:00&lt;?, ?B/s]\n\n\n\nsentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00&lt;?, ?B/s]\n\n\n\nspecial_tokens_map.json:   0%|          | 0.00/239 [00:00&lt;?, ?B/s]\n\n\n\ntokenizer.json:   0%|          | 0.00/9.08M [00:00&lt;?, ?B/s]\n\n\n\ntokenizer_config.json:   0%|          | 0.00/402 [00:00&lt;?, ?B/s]\n\n\n\nmodules.json:   0%|          | 0.00/229 [00:00&lt;?, ?B/s]\n\n\nItems in the database 2\n[{'text': 'Sample text 1'}]\n</code></pre>"},{"location":"usage-examples/#2-text-embedding-and-searching","title":"2. Text Embedding and Searching","text":"<pre><code>ste = SentenceTransformerEmbedder(# optional / adaptor parameters\n                                  processing_type = '',\n                                  tbatch_size = 500,\n                                  max_workers = 2,\n                                  # sentence transformer parameters\n                                  model_name_or_path = 'paraphrase-multilingual-mpnet-base-v2',)\n</code></pre> <pre><code># Single Text Embedding\nquery = \"Sample query\"\nembedded_query = ste.embed(query,\n                           # optional\n                           processing_type='')\nprint(embedded_query[0:50])\n</code></pre> <pre><code>[-0.04973586  0.09520268 -0.01219508  0.09253863 -0.02301829 -0.02721018\n  0.0568395   0.09710983  0.10683874  0.05812277  0.1322755   0.01142832\n -0.06957253  0.0698075  -0.05259365 -0.05755996  0.00816183 -0.0083684\n -0.00861256  0.01442069  0.01188816 -0.09503672  0.07125735 -0.04827785\n  0.01473162  0.01084185 -0.1048248   0.07012521 -0.04720647  0.10030048\n  0.04455933  0.02131893  0.00667914 -0.05259187  0.06822995 -0.09520472\n -0.00581363 -0.02451877 -0.00384987  0.02750723  0.06960277  0.2401375\n -0.01220019  0.05890937 -0.08468664  0.11379692 -0.03594767 -0.0565297\n -0.01621809  0.09546725]\n</code></pre> <pre><code># Batch Text Embedding\nqueries = [\"Sample query\", \"Sample query 2\"]\nembedded_query = ste.embed(queries,\n                           # optional\n                           processing_type='batch')\nprint(embedded_query[0][0:50])\nprint(\"---\")\nprint(embedded_query[1][0:50])\n</code></pre> <pre><code>[-0.04973584  0.09520271 -0.01219508  0.09253865 -0.0230183  -0.02721017\n  0.05683954  0.09710982  0.10683876  0.05812274  0.13227552  0.01142829\n -0.06957256  0.06980743 -0.05259361 -0.05755996  0.00816183 -0.00836839\n -0.00861252  0.01442068  0.01188819 -0.09503672  0.07125732 -0.04827787\n  0.01473164  0.01084186 -0.1048249   0.07012525 -0.04720649  0.10030047\n  0.04455935  0.02131895  0.00667912 -0.05259192  0.06822995 -0.09520471\n -0.00581363 -0.02451887 -0.00384988  0.02750726  0.06960279  0.2401375\n -0.01220022  0.05890937 -0.08468666  0.11379688 -0.03594765 -0.05652964\n -0.0162181   0.09546735]\n---\n[-0.05087024  0.1231768  -0.0139253   0.10524713 -0.07614321 -0.02349629\n  0.05829773  0.15128359  0.18119803  0.03745934  0.12174664  0.00639838\n -0.04045055  0.12758303 -0.06155453 -0.06736137  0.04713943 -0.04134275\n -0.12165949  0.0440988   0.01834145 -0.04796624  0.04922185 -0.00641203\n  0.01420631 -0.03602944 -0.01026761  0.09232258 -0.04927172  0.03985452\n  0.03566906  0.0833893   0.04922603 -0.09951889  0.0513812  -0.13344644\n  0.01626778 -0.01189724  0.0059921   0.05663403  0.04282105  0.26432782\n -0.01122811  0.07177631 -0.11822144  0.08731946 -0.04965353  0.03697515\n  0.08965266  0.03107021]\n</code></pre> <pre><code># Search Database\nsearch_results = handler.search_database(query, return_keys_list=[\"text\"])\n\n# Display Results\nprint(search_results)\n\n</code></pre> <pre><code>[{'text': 'Sample text 1'}]\n</code></pre>"},{"location":"usage-examples/#3-advanced-filtering-and-removal","title":"3. Advanced Filtering and Removal","text":"<pre><code># Advanced Filtering\nfilter_criteria = {\"text\": \"Sample text 1\"}\nhandler.filter_database(filter_criteria)\nfiltered_data = handler.filtered_data\nprint(f\"Filtered data {len(filtered_data)}\")\n\n# Data Removal\nhandler.remove_from_database(filter_criteria)\nprint(f\"Items left in the database {len(handler.data)}\")\n\n</code></pre> <pre><code>Filtered data 1\nItems left in the database 1\n</code></pre>"},{"location":"usage-examples/#4-testing-the-hnsw-search-algorithm","title":"4. Testing the HNSW Search Algorithm","text":"<pre><code>mss = MockerSimilaritySearch(\n    # optional\n    search_results_n = 3,\n    similarity_params = {'space':'cosine'},\n    similarity_search_type ='linear'\n)\n</code></pre> <pre><code># Create embeddings\nembeddings = [ste.embed(\"example1\"), ste.embed(\"example2\")]\n\n\n# Assuming embeddings are pre-calculated and stored in 'embeddings'\ndata_with_embeddings = {\"record1\": {\"embedding\": embeddings[0]}, \"record2\": {\"embedding\": embeddings[1]}}\nhandler.data = data_with_embeddings\n\n# HNSW Search\nquery_embedding = embeddings[0]  # Example query embedding\nlabels, distances = mss.hnsw_search(query_embedding, np.array(embeddings), k=1)\nprint(labels, distances)\n\n</code></pre> <pre><code>[0] [4.172325e-07]\n</code></pre>"},{"location":"usage-examples/#5-simulating-database-connection-and-persistence","title":"5. Simulating Database Connection and Persistence","text":"<pre><code># Establish Connection\nhandler.establish_connection()\n\n# Change and Persist Data\nhandler.insert_values([{\"text\": \"New sample text\"}], \"text\")\nhandler.save_data()\n\n# Reload Data\nhandler.establish_connection()\nprint(f\"Items in the database {len(handler.data)}\")\n\n</code></pre> <pre><code>Items in the database 2\n</code></pre>"}]}